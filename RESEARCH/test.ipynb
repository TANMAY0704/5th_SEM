{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Module.data_processing import load_data, clean_data, preprocess_data\n",
    "from Module.model_evaluation import *\n",
    "from Module.neural_network import build_cnn_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_script.py\n",
    "file_path = \"hcvdat0.csv\"\n",
    "X, y = load_data(file_path)\n",
    "\n",
    "# ... (rest of your code)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Preprocessing:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['column_name']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4500\\280574855.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Before Preprocessing:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mknn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m accuracy_before, precision_before, recall_before, f1_before, auc_roc_before = train_and_evaluate_model(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknn_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pande\\OneDrive\\Documents\\GitHub\\5th_SEM\\RESEARCH\\Module\\model_evaluation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(model, X_train, y_train, X_test, y_test, is_nn, is_cnn, epochs, batch_size, after_preprocessing)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_and_evaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_nn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_cnn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_preprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Data Cleaning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mX_train_cleaned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mX_test_cleaned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Data Preprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pande\\OneDrive\\Documents\\GitHub\\5th_SEM\\RESEARCH\\Module\\data_processing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'column_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'Unnamed: 0'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6413\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6414\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6415\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6416\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6417\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6418\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6420\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['column_name']"
     ]
    }
   ],
   "source": [
    "print(\"Before Preprocessing:\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "accuracy_before, precision_before, recall_before, f1_before, auc_roc_before = train_and_evaluate_model(\n",
    "    model=knn_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    is_nn=False,\n",
    "    is_cnn=False,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    after_preprocessing=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nAfter Preprocessing:\")\n",
    "accuracy_after, precision_after, recall_after, f1_after, auc_roc_after = train_and_evaluate_model(\n",
    "    model=knn_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    is_nn=False,\n",
    "    is_cnn=False,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    after_preprocessing=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural Network (Before Preprocessing):\n",
      "y_numeric shape: (615,)\n",
      "Shapes before train-test split:\n",
      "X shape: (0, 13)\n",
      "y_numeric shape: (0,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pande\\OneDrive\\Documents\\GitHub\\5th_SEM\\RESEARCH\\test.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pande/OneDrive/Documents/GitHub/5th_SEM/RESEARCH/test.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# nn before preprocessing\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pande/OneDrive/Documents/GitHub/5th_SEM/RESEARCH/test.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mNeural Network (Before Preprocessing):\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pande/OneDrive/Documents/GitHub/5th_SEM/RESEARCH/test.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_train_resampled, X_test_imputed, y_train_resampled, y_test \u001b[39m=\u001b[39m preprocess_data(X, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pande/OneDrive/Documents/GitHub/5th_SEM/RESEARCH/test.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_train_resampled))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pande/OneDrive/Documents/GitHub/5th_SEM/RESEARCH/test.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m input_shape \u001b[39m=\u001b[39m (X_train_resampled\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pande\\OneDrive\\Documents\\GitHub\\5th_SEM\\RESEARCH\\Module\\data_processing.py:47\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(X, y, polynomial_degree, random_state_value)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m# Preprocessing pipeline\u001b[39;00m\n\u001b[0;32m     41\u001b[0m preprocessor \u001b[39m=\u001b[39m ColumnTransformer(\n\u001b[0;32m     42\u001b[0m     transformers\u001b[39m=\u001b[39m[\n\u001b[0;32m     43\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mnum\u001b[39m\u001b[39m'\u001b[39m, SimpleImputer(strategy\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m), numerical_cols),\n\u001b[0;32m     44\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mcat\u001b[39m\u001b[39m'\u001b[39m, OneHotEncoder(), categorical_cols)\n\u001b[0;32m     45\u001b[0m     ])\n\u001b[1;32m---> 47\u001b[0m poly_features \u001b[39m=\u001b[39m PolynomialFeatures(degree\u001b[39m=\u001b[39mpolynomial_degree, include_bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m \u001b[39m# Create a pipeline\u001b[39;00m\n\u001b[0;32m     50\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline([\n\u001b[0;32m     51\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m'\u001b[39m, preprocessor),\n\u001b[0;32m     52\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mpoly_features\u001b[39m\u001b[39m'\u001b[39m, poly_features)\n\u001b[0;32m     53\u001b[0m ])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:2649\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2646\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[0;32m   2648\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m-> 2649\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2650\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[0;32m   2651\u001b[0m )\n\u001b[0;32m   2653\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m   2654\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:2305\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2302\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[0;32m   2304\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2306\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWith n_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and train_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2307\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2308\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maforementioned parameters.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2309\u001b[0m     )\n\u001b[0;32m   2311\u001b[0m \u001b[39mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# nn before preprocessing\n",
    "print(\"\\nNeural Network (Before Preprocessing):\")\n",
    "X_train_resampled, X_test_imputed, y_train_resampled, y_test = preprocess_data(X, y)\n",
    "num_classes = len(np.unique(y_train_resampled))\n",
    "input_shape = (X_train_resampled.shape[1], 1)\n",
    "X_train_reshaped = X_train_resampled.values.reshape(X_train_resampled.shape[0], X_train_resampled.shape[1], 1)\n",
    "X_test_reshaped = X_test_imputed.values.reshape(X_test_imputed.shape[0], X_test_imputed.shape[1], 1)\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "\n",
    "nn_accuracy_before, nn_precision_before, nn_recall_before, nn_f1_before, nn_roc_auc_before = train_and_evaluate_nn(model, X_train_reshaped, y_train_resampled, X_test_reshaped, y_test, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn before\n",
    "print(\"\\nCNN (Before Preprocessing):\")\n",
    "X_train_resampled, X_test_imputed, y_train_resampled, y_test = preprocess_data(X, y)\n",
    "num_classes = len(np.unique(y_train_resampled))\n",
    "input_shape = (X_train_resampled.shape[1], 1)\n",
    "X_train_reshaped = X_train_resampled.values.reshape(X_train_resampled.shape[0], X_train_resampled.shape[1], 1)\n",
    "X_test_reshaped = X_test_imputed.values.reshape(X_test_imputed.shape[0], X_test_imputed.shape[1], 1)\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "\n",
    "cnn_accuracy_before, cnn_precision_before, cnn_recall_before, cnn_f1_before, cnn_roc_auc_before = train_and_evaluate_cnn(model, X_train_reshaped, y_train_resampled, X_test_reshaped, y_test, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nKNN Classifier (After Preprocessing):\")\n",
    "# Assuming PRINT_AUC is set to True for these evaluations\n",
    "knn_accuracy_after, knn_precision_after, knn_recall_after, knn_f1_after, _ = train_and_evaluate_ml(KNeighborsClassifier(n_neighbors=5), X_train, X_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDecision Tree Classifier (After Preprocessing):\")\n",
    "dt_accuracy_after, dt_precision_after, dt_recall_after, dt_f1_after, _ = train_and_evaluate_ml(DecisionTreeClassifier(random_state=random_state_value), X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRandom Forest Classifier (After Preprocessing):\")\n",
    "rf_accuracy_after, rf_precision_after, rf_recall_after, rf_f1_after, _ = train_and_evaluate_ml(RandomForestClassifier(random_state=random_state_value), X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSVM Classifier (After Preprocessing):\")\n",
    "svm_accuracy_after, svm_precision_after, svm_recall_after, svm_f1_after, _ = train_and_evaluate_ml(SVC(probability=True), X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn, X_test_nn, y_train_nn, y_test_nn = preprocess_data(X, y)\n",
    "\n",
    "print(\"\\nNeural Network Classifier (After Preprocessing):\")\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(128, input_dim=X_train_nn.shape[1], activation='relu'))\n",
    "model_nn.add(Dense(64, activation='relu'))\n",
    "model_nn.add(Dense(num_classes, activation='softmax'))  \n",
    "model_nn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Assuming you have the nn and cnn values, replace them with the actual values\n",
    "nn_accuracy_after, nn_precision_after, nn_recall_after, nn_f1_after, nn_roc_auc_after = train_and_evaluate_nn(model_nn, X_train_nn, y_train_nn, X_test_nn, y_test_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_cnn = (X_train_nn.shape[1], 1) \n",
    "X_train_nn_cnn = X_train_nn.values.reshape(X_train_nn.shape[0], X_train_nn.shape[1], 1)\n",
    "X_test_nn_cnn = X_test_nn.values.reshape(X_test_nn.shape[0], X_test_nn.shape[1], 1)\n",
    "\n",
    "print(\"\\nCNN Classifier (After Preprocessing):\")\n",
    "cnn_model_after = build_cnn_model(input_shape_cnn, num_classes)\n",
    "cnn_accuracy_after, cnn_precision_after, cnn_recall_after, cnn_f1_after, _ = train_and_evaluate_nn(cnn_model_after, X_train_nn_cnn, y_train_nn, X_test_nn_cnn, y_test_nn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Analysis\n",
    "\n",
    "In this section, we delve into a comprehensive analysis of key performance metrics for various classifiers before and after preprocessing. Understanding these metrics is crucial for assessing the effectiveness of machine learning models in our specific context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_after,classifiers_before = ['KNN', 'Decision Tree', 'Random Forest', 'SVM', 'Neural Network', 'CNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy_values_before = [knn_accuracy_before, dt_accuracy_before, rf_accuracy_before, svm_accuracy_before, nn_accuracy_before, cnn_accuracy_before]\n",
    "accuracy_values_after = [knn_accuracy_after, dt_accuracy_after, rf_accuracy_after, svm_accuracy_after, nn_accuracy_after, cnn_accuracy_after]\n",
    "print_and_plot_accuracy(classifiers_before, accuracy_values_before, accuracy_values_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_values_before = [knn_precision_before, dt_precision_before, rf_precision_before, svm_precision_before, nn_precision_before, cnn_precision_before]\n",
    "precision_values_after = [knn_precision_after, dt_precision_after, rf_precision_after, svm_precision_after, nn_precision_after, cnn_precision_after]\n",
    "print_and_plot_metrics_line(classifiers_before, precision_values_before, precision_values_after, 'Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_values_before = [knn_recall_before, dt_recall_before, rf_recall_before, svm_recall_before, nn_recall_before, cnn_recall_before]\n",
    "recall_values_after = [knn_recall_after, dt_recall_after, rf_recall_after, svm_recall_after, nn_recall_after, cnn_recall_after]\n",
    "print_and_plot_metrics_line(classifiers_before, recall_values_before, recall_values_after, 'Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_values_before = [knn_f1_before, dt_f1_before, rf_f1_before, svm_f1_before, nn_f1_before, cnn_f1_before]\n",
    "f1_values_after = [knn_f1_after, dt_f1_after, rf_f1_after, svm_f1_after, nn_f1_after, cnn_f1_after]\n",
    "print_and_plot_metrics_line(classifiers_before, f1_values_before, f1_values_after, 'F1 Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In evaluating the performance of various classifiers before and after preprocessing on a HCV dataset, several key observations emerge.\n",
    "\n",
    "### Before Preprocessing:\n",
    "\n",
    "- **KNN, Decision Tree, Random Forest, SVM, Neural Network, CNN:**\n",
    "  - The classifiers demonstrated moderate to good performance in accuracy, precision, recall, and F1 score.\n",
    "  - The results suggest that while these models provided reasonable predictions, there was room for improvement, especially in handling class imbalances and capturing complex patterns in the data.\n",
    "\n",
    "### After Preprocessing:\n",
    "\n",
    "- **KNN:**\n",
    "  - Witnessed a notable improvement in accuracy, precision, recall, and F1 score after preprocessing.\n",
    "  - Achieved high scores across all metrics, making it a standout performer after data preparation.\n",
    "\n",
    "- **Decision Tree:**\n",
    "  - Maintained similar accuracy while showing enhanced precision, recall, and F1 score after preprocessing.\n",
    "  - Remains a stable choice, particularly considering its interpretability.\n",
    "\n",
    "- **Random Forest:**\n",
    "  - Exhibited substantial improvements across all metrics after preprocessing, showcasing its adaptability to cleaner data.\n",
    "  - Achieved high accuracy and precision, positioning it as a robust performer.\n",
    "\n",
    "- **SVM:**\n",
    "  - Displayed improvements in accuracy, precision, recall, and F1 score after preprocessing.\n",
    "  - Maintained competitive performance, particularly in precision.\n",
    "\n",
    "- **Neural Network and CNN:**\n",
    "  - Outperformed other models in terms of accuracy, precision, recall, and F1 score.\n",
    "  - Demonstrated the capacity to capture complex patterns in the data, especially after preprocessing.\n",
    "\n",
    "### Overall:\n",
    "\n",
    "- **Random Forest and SVM** showed substantial improvements after preprocessing, establishing them as robust choices.\n",
    "- **Neural Network and CNN** demonstrated superior performance, especially in capturing intricate relationships within the data.\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "- For interpretable models, Decision Tree or SVM may be preferred, balancing between performance and transparency.\n",
    "- For complex relationships, Neural Network or CNN might be more suitable, offering high accuracy and capturing intricate patterns.\n",
    "\n",
    "These conclusions are based on the specific performance metrics of each classifier, providing insights into their strengths and areas of improvement after preprocessing. The choice of a model depends on the specific requirements of the application, considering factors such as interpretability, performance, and the nature of the dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
